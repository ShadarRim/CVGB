{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV04.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WAf8DcOZlDa"
      },
      "source": [
        "# Общее решение\n",
        "\n",
        "Если бы удалось нормально скачать данные на colab, тот вот этот код был бы целиком рабочий. Но в итоге мешает то, что coalb прерывает сессии скачивания. Примечание: код на скачивание картинок отдельно ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifpv2VZUVYTK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGkM0aNAVheY"
      },
      "source": [
        "class Dataset():\n",
        "\n",
        "    def crop_images(self, img, inp_size, random_crop=False):\n",
        "        shape = tf.shape(img)\n",
        "        pad = (\n",
        "            [0, tf.maximum(inp_size - shape[0], 0)],\n",
        "            [0, tf.maximum(inp_size - shape[1], 0)],\n",
        "            [0, 0],\n",
        "        )\n",
        "        img = tf.pad(img, pad)\n",
        "\n",
        "        if random_crop:\n",
        "            img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n",
        "        else: # central crop\n",
        "            shape = tf.shape(img)\n",
        "            ho = (shape[0] - inp_size) // 2\n",
        "            wo = (shape[1] - inp_size) // 2\n",
        "            img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n",
        "\n",
        "        return img\n",
        "\n",
        "    def train_dataset(self, batch_size, epochs, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = True\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.repeat(epochs)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def val_dataset(self, batch_size, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = False\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWn6hHvSVlDw"
      },
      "source": [
        "class COCO_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, sublist):\n",
        "        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n",
        "        self.coco = COCO(ann_file_fpath)\n",
        "        self.cat_ids = self.coco.getCatIds(catNms=['cat'])\n",
        "        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n",
        "\n",
        "    def read_images(self, img_id):\n",
        "        img_id = int(img_id.numpy())\n",
        "        img_data = self.coco.loadImgs(img_id)[0]\n",
        "        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
        "\n",
        "        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
        "        if len(img.shape) == 2:\n",
        "            img = np.tile(img[..., None], (1, 1, 3))\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "        for i in range(len(anns)):\n",
        "            mask_class += self.coco.annToMask(anns[i])\n",
        "        mask_class = (mask_class > 0).astype(np.uint8)\n",
        "\n",
        "        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n",
        "\n",
        "        return img_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrZTITgQZNxk"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 1 \n",
        "inp_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqNXGcZMVmvx"
      },
      "source": [
        "COCO_dataset_train = COCO_Dataset('train')\n",
        "COCO_dataset_val = COCO_Dataset('val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL6QxyQnZGzH"
      },
      "source": [
        "train_ds = COCO_dataset_train.train_dataset(batch_size, 1, inp_size)\n",
        "val_ds = COCO_dataset_val.val_dataset(batch_size, inp_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WB6DxhRZVPh"
      },
      "source": [
        "def build_model():\n",
        "    x = tf.keras.layers.Input((INP_SIZE, INP_SIZE, 3))\n",
        "    \n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    out1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.MaxPool2D((2, 2))(out1)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out2 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.MaxPool2D((2, 2))(out2)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out3 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.MaxPool2D((2, 2))(out3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out4 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.MaxPool2D((2, 2))(out4)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    out = tf.keras.layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out4, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    out = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out3, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    out = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out2, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    out = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out1, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(1, (3, 3), padding='same', activation='sigmoid')(out)\n",
        "\n",
        "    return tf.keras.Model(inputs=x, outputs=out)\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kHP7j5TZW8X"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXFkomupZZiG"
      },
      "source": [
        "model.fit(train_ds, batch_size=batch_size, epochs=epichs, validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzlHJdvaZ3Jw"
      },
      "source": [
        "# Скачивание картинок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pozu0bx9aCLF"
      },
      "source": [
        "coco = COCO('data/annotations/instances_train2017.json')\n",
        "cats = ['person']\n",
        "nms=[cat['name'] for cat in cats]\n",
        "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
        "\n",
        "catIds = coco.getCatIds(catNms=['person'])\n",
        "imgIds = coco.getImgIds(catIds=catIds )\n",
        "images = coco.loadImgs(imgIds)\n",
        "print(\"imgIds: \", imgIds)\n",
        "print(\"images: \", images)\n",
        "\n",
        "for im in images:\n",
        "    print(\"im: \", im)\n",
        "    img_data = requests.get(im['coco_url']).content\n",
        "with open('downloaded_images/' + im['file_name'], 'wb') as handler:\n",
        "  handler.write(img_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}